\documentclass[12pt,draftcls,onecolumn]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}

\newcommand{\Fp}{\mathbb{Z}_p}
\newcommand{\sk}{\texttt{sk}}
\newcommand{\pk}{\texttt{pk}}
\newcommand{\id}{\texttt{id}}
\newcommand{\seed}{\texttt{seed}}
\newcommand{\ind}{\texttt{index}}
\newcommand{\out}{\texttt{output}}
\newcommand{\cmt}{\texttt{commit}}

\newcommand{\Alloc}{\textsc{Alloc}}
\newcommand{\mask}{\textsc{mask}}

\title{Dilithium: Subspace Consensus v2}
\author{Chen Feng with Subspace R\&D Team}
%\date{December 4 2022}

\begin{document}

\maketitle


\section{Building Blocks}

In this section, we review several building blocks for Subspace Consensus v2 called {\bf Dilithium}. 
Our main objective is twofold: improving {\bf user experience} and enhancing {\bf security level}.
In particular, we would like to optimize the following user-experience metrics as much as possible
\begin{itemize}
    \item initialization (or setup) time: a few hours to days (depending on the disk space)
    \item proof-generation time: less than one second
    \item proof size: less than 500 Bytes
    \item verification time: much less than one second, ideally in milliseconds
\end{itemize}
At the same time, we aim to achieve the highest level of {\bf consensus security} among existing Proof-of-Storage protocols. 
%We aim to achieve the following objectives

The (relative) small proof size prevents us from using graph-labeling-based constructions (such as those with depth robust graphs used in Filecoin), encouraging us to develop new innovations. We propose to combine three ingredients, namely, polynomial commitment (with constant-size proof size), erasure coding, and Chia PoS tables (as a memory-bound function), to address our design challenge.  

\subsection{Creating Storage Coins}

We divide a file $F$ into $n$ pieces $\{ d_0, d_1, \ldots, d_{n-1}\}$, each of equal size\footnote{We can view $F$ as the blockchain history. In general, $F$ grows over time. Here, we consider the case that $F$ is fixed and defer the general case to our specification.}. 
Without loss of generality, we view each piece as a row vector of length $\ell$ over $\Fp$  (i.e., $d_i \in \Fp^\ell$)\footnote{Here, we choose $\Fp$ because we would like to apply KZG polynomial commitment later.}.
Then, $F$ can be viewed as a matrix of size $n \times \ell$ over $\Fp$.
Alternatively, each piece $d_i$ can be viewed as a polynomial $f_i(x)$ over $\Fp$ of degree at most $\ell - 1$. 
Then, $F$ can be viewed as a collection of $n$ polynomials $\{ f_i(x) \}_{i = 0}^{n-1}$. 

We assume that each farmer creates a farmer ID $\id$ uniformly at random over some domain. For example, $\id$ can be a (cryptographic) hash output of a farmer's public key $\pk$ (i.e., $\id = H(\pk)$).
We also assume that each farmer selects $m$ pieces (out of $n$ pieces) in a random yet verifiable way based on its farmer ID.
We denote these $m$ pieces (or equivalently, polynomials) by $\{g_0^{\id}(x), \ldots, g_{m-1}^{\id}(x) \}$.
For example, each $g_i^{\id}(x)$ can be selected as $f_{(\id + i)\% n}(x)$, where $\% n$ is the mod $n$ operation\footnote{By abuse of notation, we convert $\id$ (from its domain) into an integer here.}.
As another example\footnote{This example corresponds to a standard coupon collector's problem. In order to make sure that every piece is selected by some farmer, we need a total of $O\left( \frac{n \ln n}{m} \right)$ farmers.}, each $g_i^{\id}(x)$ can be selected as $f_{H(\id, i)\% n}(x)$.

We are now ready to explain how a farmer creates storage coins. Let
\[
F^{\id}(x) = \begin{bmatrix} g_0^{\id}(x)\\ g_1^{\id}(x)\\  \vdots \\ g_{m-1}^{\id}(x) \end{bmatrix}
\]
be a column vector of $m$ polynomials. 
Then, we can evaluate $F^{\id}(x)$ at the following $\ell$ points: $\id$, $\id + 1$, $\ldots$, $\id + \ell - 1$\footnote{Again, by abuse of notation, we convert $\id$ into an element in $\Fp$.}.
Each evaluation $F^{\id}(\id + j)$ is a column vector of length $m$ over $\Fp$. We  call it a {\bf storage coin}
associated with $\id$ at point $\id + j$.
For the purpose of efficiency, a farmer can evaluate $\ell$ points simultaneously for every polynomial $g_i^{\id}(x)$
by using some fast polynomial-evaluation algorithms with $\mathcal{O}(\ell \log^2(\ell))$ complexity.
Alternatively, we can evaluate $F^{\id}(x)$ at another set of $\ell$ points: $\id$, $\id \cdot \omega$, $\ldots$, $\id \cdot \omega^{\ell - 1}$, where $\omega$ is a primitive root of unity over $\Fp$ with $\omega^\ell = 1$ or $\omega^{2 \ell} = 1$.


Why is a storage coin useful? If we collect all $\ell$ storage coins associated with $\id$, we can recover $F^{\id}(x)$ through polynomial interpolation.
In particular, if we collect all $\ell$ evaluation points for some $g_i^{\id}(x)$, we can recover $g_i^{\id}(x)$ through polynomial interpolation.
(There are some fast algorithms for polynomial interpolation with $\mathcal{O}(\ell \log^2(\ell))$ complexity.)
In other words, storage coins allow us to recover some pieces of the file $F$ efficiently. Hence, they represent {\bf useful storage} for $F$.

How can a farmer prove to some verifier that a storage coin $F^{\id}(\id + j)$ at point $\id + j$ is created correctly? This is a standard polynomial commitment problem. For example, we can use the
KZG commitment scheme. Let $A_i$ be the KZG commitment of $f_i(x)$ for $i \in \{0, 1, \ldots, n-1\}$. 
We consider the following two cases.
\begin{enumerate}
    \item The verifier knows $\{ A_i \}_{i = 0}^{n - 1}$. In this case, the farmer just needs to create a KZG proof for the polynomial evaluation $g_i^{\id}(x)$ at point $\id + j$, because the verifier can check whether the choice of polynomial $g_i^{\id}(x)$ is correct. For example, if $g_i^{\id}(x)$ is selected as $f_{(\id + i)\% n}(x)$, the verifier can check whether the KZG proof is consistent with $A_{(\id + i)\% n}$. 
    \item The verifier doesn't know any $A_i$. In this case, we can create a KZG commitment $T$ for $\{ A_i \}_{i = 0}^{n - 1}$ and then give $T$ to the verifier\footnote{Since $A_i$ is not an element in $\Fp$, we cannot apply KZG directly. Instead, we need to hash $A_i$ so that $H(A_i) \in \Fp$.}.  The farmer needs to provide two KZG proofs: one for the polynomial evaluation $g_i^{\id}(x)$ at point $\id + j$ and the other for the correctness of $g_i^{\id}(x)$. (That is, $g_i^{\id}(x)$ is chosen correctly according to our rule. For example, the commitment of $g_i^{\id}(x)$ is indeed $A_{(\id + i)\% n}$, which can be proven by using $T$.)
\end{enumerate}


\subsection{Masking Storage Coins}

We propose to use a memory-bound (or memory-bandwidth-hard) function to ``mask" storage coins. The function $\mask(\cdot)$ should have the following three properties

\begin{enumerate}
    \item It has a tunable parameter $k$ to adjust the memory requirement. 
    \item It has two inputs $\seed$ and $\ind$, where $\seed$ determines the memory content (e.g., some function tables)
    and $\ind \in \{0, 1, \ldots, 2^k - 1 \}$ specifies in-memory computation.
    \item It has a single output (of size depending on $k$) that can be verified with a small amount of memory and time.
\end{enumerate}


%For example, $\seed$ determines some computation tables 
Note that $\mask(\seed, \ind; k)$ and $\mask(\seed, \ind + 1; k)$ share the same memory content, but $\mask(\seed, \ind; k)$
and $\mask(\seed + 1, \ind; k)$ don't. For notational simplicity, we use $[2^k]$ to denote the set $\{0, 1, \ldots, 2^k - 1 \}$.

Next, we explain how to mask a storage coin
\[
F^{\id}(\id + j) = \begin{bmatrix} g_0^{\id}(\id + j)\\ g_1^{\id}(\id + j)\\  \vdots \\ g_{m-1}^{\id}(\id + j) \end{bmatrix}.
\]
We denote by $\cmt\left(g_i^{\id}(x)\right)$ the KZG commitment of $g_i^{\id}(x)$.
For each $g_i^{\id}(\id + j)$ (where $j \in [2^k]$), we set
\[
\seed = \id \oplus H\left( \cmt\left(g_i^{\id}(x)\right) \right) \mbox{ and } \ind = j.
\]
Then, we compute $g_i^{\id}(\id + j) \oplus H\left( \mask(\seed, \ind; k) \right)$ as a masked version of $g_i^{\id}(\id + j)$, denoted by $\tilde{g}_i^{\id}(\id + j)$.
Applying this procedure to all $\{ g_i^{\id}(\id + j) \}_{i = 0}^{m - 1}$, we obtain a {\bf masked storage coin}.
For efficient use of memory, a farmer can mask $\ell$ points for some polynomial $g_i^{\id}(x)$ (in order to reuse the memory content) and then move to another polynomial, say $g_{i+1}^{\id}(x)$.
Alternatively,
we can use $H\left( \mask(\seed, j; k) \right)$ to mask $g_i^{\id}(\id \cdot \omega^j)$ instead of $g_i^{\id}(\id + j)$, where $\omega$ is a primitive root of unity\footnote{In the C-KZG library, $\omega$ is chosen such that $\omega^{2 \ell} = 1$.}.

\subsection{Creating Random Challenges}

We start with a high-level overview. At each time slot (say, one second), every farmer observes some global randomness (also referred to as the global challenge). 
Based on this global challenge, each farmer determines exactly one masked storage coin (out of $\ell$ masked storage coins) to scan. Since a storage coin contains $m$ elements in $\Fp$, this gives a farmer $m$ ``tickets'' to win the lottery. A ticket is called a winning ticket if it is close enough to the global challenge in terms of the Hamming distance.

Let $\mathcal{C}_t$ be the global challenge at time slot $t$. Each farmer computes $H(\mathcal{C}_t, \id)$ mod $\ell$ in order to decide which storage coin to scan.
For example, if 
\[
H(\mathcal{C}_t, \id) \mbox{ mod } \ell = j,
\]
then the farmer will scan a masked version of $F^{\id}(\id + j)$, hoping to find an element that is close enough to $\mathcal{C}_t$ in terms of the Hamming distance. 
Alternatively, if $\mathcal{C}_t$ and $\id$ share the same domain, each farmer can compute $\mathcal{C}_t \oplus \id$ mod $\ell$ to decide which storage coin to scan, since $\oplus$ operation is easier than $H(\cdot)$ operation. 

In the above construction, anyone in the system can figure out whether a particular farmer has a winning ticket, because all the operations depend on the farmer's public key $\pk$ (through $\id$) but not on the secret key $\sk$.  
There is another way of creating random challenges that protect this privacy. 
Each farmer creates a {\bf local challenge} by signing the global challenge $\mathcal{C}_t$ with its secret key $\sk$. Based on its local challenge, each farmer determines exactly one storage coin (in the same way as before) to find a winning ticket that is close enough to its local challenge. A farmer can reveal its local challenge only after a winning ticket is found.

\subsection{Putting Everything Together}

Recall that the file $F$ consists of $n$ pieces $\{d_i\}_{i = 0}^{n-1}$, which can be viewed as $n$ polynomials $\{ f_i(x) \}_{i = 0}^{n-1}$. Recall that
$A_i$ is the KZG commitment of $f_i(x)$ and $T$ is the KZG commitment of $(H(A_0), \ldots, H(A_{n-1}))$. We assume that $T$ is public information.
Let $\pi_i$ be the KZG proof for $H(A_i)$. With $\pi_i$, anyone in the system can verify whether $A_i$ is consistent with the public information $T$.

Each farmer generates a key pair $(\sk, \pk)$ and derives its farmer ID $\id$ (e.g., $\id = H(\pk)$).
With a given $\id$, the farmer selects $m$ polynomials $\{g_i^{\id}(x) \}_{i = 0}^{m - 1}$ and retrieves their KZG commitments $\{\cmt\left(g_i^{\id}(x) \right \}_{i = 0}^{m - 1}$
together with the proofs with respect to $T$. Then, the farmer creates $\ell$ storage coins 
$\{ F^{\id}(\id + j) \}_{j = 0}^{\ell - 1}$ and generates their masked versions by using the function $\mask(\cdot)$ as described before.
Finally, the farmer stores $\ell$ masked storage coins as well as some metadata (i.e., $m$ commitments $\{\cmt\left(g_i^{\id}(x) \right \}_{i = 0}^{m - 1}$ together with their proofs).
This process is often called {\bf plotting} in the literature.

Recall that a global challenge $\mathcal{C}_t$ is generated at time slot $t$, based on which each farmer collects $m$ lottery tickets from one masked storage coin. If a farmer finds a winning ticket, it has to prove the following
\begin{itemize}
    \item the winning ticket (say, $\tilde{g}_i^{\id}(\id + j)$) is indeed close enough to $\mathcal{C}_t$
    \item the unmasked element ${g}_i^{\id}(\id + j)$ is correct
\end{itemize}
This process is called {\bf auditing} in the literature. 



% \subsection{Advantages of Our Construction}

% Here, we summarize several advantages of our proposed construction before conducting a formal analysis.
% \begin{enumerate}
%     \item The use of storage coins enlarges the design space. In PoR, a file is the smallest unit. In the ECP paper, a RS coded piece is the smallest unit. In our construction, a polynomial coded piece is the smallest unit.
%     \item The enlarged design space makes it easier for us to choose good parameters.
%     \item The usefulness of storage coins can be verified through standard KZG, which implies low communication and fast verification.
%     \item Unlike proof-of-replication, farmers have more incentives to store encodings $\{ R_j(\id) \}_{j = 1}^L$ because these encodings are lottery tickets (which are hard to compute on-the-fly).
%     \item Once a farmer has one storage coin, it can participate in the lottery.
%     \item Storage coins support a dynamic setting.
%     \item The size of a storage coin is relatively small, making it easier to apply slow encoding. I suspect that even the second solution described above might be sufficient.
% \end{enumerate}


\section{Extensions}

Our basic construction relies on an ``ideal'' function $\mask(\cdot)$ that has three properties. The first two properties are easy to achieve, but not the third one. Indeed, we don't have a concrete example of $\mask(\cdot)$ at the time of writing. Instead, we have a weaker version of $\mask(\cdot)$ in which the third property is relaxed. In this version, $\seed$ and $k$ determine a random function $h(\cdot)$ that requires a significant amount 
of space to invert, and the output of $\mask(\cdot)$ is a pre-image of $\ind$ under $h$. Since the pre-image (of $\ind$ under $h$) can be empty or a set with multiple elements, the output of $\mask(\cdot)$ is not always a single value. We would like to show that this is not an issue.
To this end, we consider three possible examples of $\mask(\cdot)$.

\noindent {\bf Example 1:} $h(\cdot)$ is a random function with its domain and co-domain being the set
\[
[2^k] \triangleq \{ 0, 1, \ldots, 2^k - 1  \}.
\]
For this example\footnote{Note that the resulting $\mask(\cdot)$ from Example~1 is not a memory-bound function. In other words, Example~1 is just a warm-up example.}, we have the following observations:
\begin{itemize}
    \item $\ind \in [2^k]$;
    \item Around $1/e$ fraction of $\ind$ has no pre-images for large $k$;
    \item The maximum number of pre-images is upper bounded by $\ln(2^k)/\ln\left( \ln(2^k) \right)$ with high probability.
\end{itemize}

In order to use $h(\cdot)$, we consider three cases for some $\ind \in [2^k]$.
\begin{enumerate}
    \item $\ind$ has a unique pre-image under $h$. In this case, we simply compute $g_i^{\id}(\id + \ind) \oplus H\left( h^{-1}(\ind) \right)$ as a masked version of $g_i^{\id}(\id + \ind)$ as we did before.
    \item $\ind$ has no pre-image under $h$. In this case, we skip $g_i^{\id}(\id + \ind)$, leaving the element $g_i^{\id}(\id + \ind)$ unmasked.
    \item $\ind$ has multiple pre-images under $h$. In this case, we mask $g_i^{\id}(\id + \ind)$ with one such pre-image.
\end{enumerate}
Then, for each storage coin $F^{\id}(\id + \ind)$ at point $\id + \ind$, we only store its masked elements (and discard its unmasked elements).

Previously, we need a total of $\ell$ storage coins (in order to recover the original pieces). How many storage coins do we need now?
Clearly, this number $L$ should be between $\ell$ and $2^k$ (i.e., $\ell < L \le 2^k$).
In fact, it is a standard balls-and-bins problem. 
Suppose that we have $2^k$ balls and $2^k$ bins with each ball placed into a bin uniformly at random and independent of each other.
Then, the fraction of empty bins is approximately $\frac{1}{e}$ for large $2^k$.
In other words, the fraction of non-empty bins is approximately $1 - \frac{1}{e}$.
This implies that $\frac{\ell}{L} \ge 1 - \frac{1}{e}$ if we would like to have at least $\ell$ non-empty bins out of the first $L$ bins. 
In fact, the probability of an ``error event'' (of having fewer than $\ell$ non-empty bins out of the first $L$ bins) can be approximately bounded by $\exp\left(- 2^k D_{KL}(1 - \ell/L, 1/e) \right)$. The larger $L$ is, the larger the term $D_{KL}(1 - \ell/L, 1/e)$ is, and the smaller the error probability.
This can be used as a guideline for choosing $L$.

%To see this, on the one hand, the fraction of empty bins is approximately $1/e$ for large $k$, and on the other hand, the fraction of non-empty bins should be no smaller than $\ell/2^{k}$ in order to ``mask'' $\ell$ polynomial evaluations.
%(To do: cite more results here.)

%A concern here: the variance creates grinding opportunities (because the number of tickets is no longer fixed). Luckily, we can show that the variance is indeed small.

{\bf Example 2:} $h(\cdot)$ is constructed via a random function $g : [2^k] \times [2^k] \to [2^k]$
and a random permutation $f: [2^k] \to [2^k]$ by following the Beyond-Hellman paper. Specifically, 
$h(\cdot)$ is defined as $h(x) = g(x, x')$, where $f(x) = \pi( f(x') )$ with $\pi$ being any involution
without a fixed point (e.g., flipping all the bits). In this example, since any pair $(x, x')$ with $f(x) = \pi( f(x') )$ can be viewed as a ball, our analysis for Example~1 still applies here. Also, a pre-image of $h(\cdot)$ is of the form $(x, x')$ rather than $x$ only, because otherwise the verifier has to find $x'$.

{\bf Example 3:} $h(\cdot)$ is constructed via Chia PoS tables. In this example, an output is of the form $(x_1, x_2, \ldots, x_{64})$. Assume that all seven functions $f_1(x), \ldots, f_7(x)$  are random functions.
Then, for any \emph{weakly distinct} tuple $(x_1, x_2, \ldots, x_{64})$, the probability it passes the challenge is $2^{-64k}$.
Note that in Example~2, for any \emph{weakly distinct} tuple $(x_1, x_2)$, the probability it passes the challenge is approximately $2^{-2k}$. Therefore, our analysis for Example~2 is a good approximation.


We now understand the extensions of our basic construction. Before conducting a formal analysis, let us present several possible attacks and their mitigation methods in order to better understand our construction.

{\bf Attack 1:} If $\mask(\seed, \ind; k)$ returns multiple outputs, an attacker can produce multiple tickets instead of one.

\begin{itemize}
    \item Mitigation Method 1: If the verifier can figure out which output is the first, then this issue can be resolved.
    \item Mitigation Method 2: We allow the farmers to produce multiple tickets from multiple outputs. This introduces some randomness, which can be bounded by using the analysis above.
\end{itemize}

{\bf Attack 2:} The attacker stores the Chia PoS tables on disk instead of the masked storage coins.

\begin{itemize}
    \item Mitigation Method 1: We can choose $k$ so that Chia PoS tables are sufficiently larger than the corresponding masked storage coins.
    \item Mitigation Method 2: We estimate the amount of additional disk look-ups and then use an economic security argument.
\end{itemize}

{\bf Attack 3:} The attacker stores the Chia PoS tables on memory.

\begin{itemize}
    \item We show that the memory storage cost is larger than the disk storage cost.
\end{itemize}

{\bf Note:} Both Attack 2 and Attack 3 can be well mitigated by using a large $k$. However, we have some practical upper bound on $k$. So, we need a {\bf tight analysis} to show that a relatively small $k$ is still OK.

{\bf Attack 4:} The attacker exploits the case of expiring pieces. Since this case is not considered in our current model and analysis, there might be some potential attacks here.

%{\bf Attack 5:} On DSN load balancing.


\section{Economic Security Analysis}

%\subsection{System model}

{\bf Outline:} We can use a hardware architecture model to reason about economic security. In particular, we will focus on the memory IO and Hash computation (modelled as an oracle access). We will model the energy cost as a linear combination of the memory IO and oracle access and then derive a lower bounder for the energy cost. We will then include the setup cost. Similar models have already been used in Ling Ren's PhD thesis and other works.



{\bf Intuition:} First of all, we consider three very simple cases.
\begin{itemize}
    \item If an attacker generates the Chia PoS tables on the fly, then the memory IO is lower bounded by the size of the tables.
    \item If an attacker stores the Chia PoS tables on memory, then the memory storage cost is higher than the disk storage cost.
    \item If an attacker stores the Chia PoS tables on disk, then we can make the size of tables larger than the masked storage coins.
\end{itemize}

Next, for Hellman's attacks, we can lower bound their memory IO and computational costs.
Here, we need to consider more general attacks because the attacking goal here is to minimize the total cost.

{\bf Proof Sketch:} Our proof is based on the following ingredients. 

\begin{itemize}
    \item Space-time tradeoff lower bound (from the ``Beyond Hellman'' paper): 
    any adversary who gets $S$ bits of auxiliary information, makes at most $T$
    oracle queries, and inverts $h(\cdot)$ (defined in Example~2 above) on an
    $\epsilon$ fraction of outputs must satisfy $S^2 \cdot T \in \Omega(\epsilon^2 N^2)$ (where $N$
    is the domain size and $N = 2^k$ in our notation).
    \item Energy cost in the parallel random oracle model (from the ``Bandwidth-Hard Functions'' paper): a formal definition of energy costs is given based on a simple memory-cache model.
\end{itemize}

Roughly, $S$ bits of auxiliary information can be computed in cache and then transferred to memory (which incurs memory IO with a unit cost $c_b$), and $T$ oracle queries can be charged with a unit cost $c_r$.
This allows us to evaluate the energy cost for any adversary. Note that this cost depends on $k$, which can be adjusted so that the cost is higher than the energy cost of honest farmers.

\section{Consensus Security Analysis}

Our key inspirations are the following.

\begin{itemize}
    \item When considering longest-chain protocols, Proof-of-Stake (PoS) is less secure than PoW as it presents many additional vulnerabilities (such as long-range attacks). 
    \item The best we can show is that Proof-of-Archival-Storage (PoAS) stands in the middle.
\end{itemize}

\subsection{System model}

%On Explicit Constructions of Extremely Depth Robust Graphs
%ZigZag horizontal DRG + vertical DRG
%Temporary Block Withholding Attacks on Filecoin's Expected Consensus

The protocol proceeds in slots of duration $\tau$ (where $\tau$ is one second in our PoAS setup). For simplicity, we consider a fixed set of $N$ nodes with equal capability. We
are interested in the large system regime $N \to \infty$. In each slot, each node can win the lottery with probability $\rho / N$,
independently of other nodes and slots. When a malicious node wins the lottery at slot $t$, it can create multiple blocks, which is a behavior called equivocations. (Note that equivocations never happen in PoW but can appear in PoS and PoAS.)




\subsection{Analysis}

{\bf Proof Sketch:}
Following the paper ``Security of Blockchains at Capacity'' (which is available online),  we can define \emph{good} slots, \emph{bad} slots, and \emph{empty} slots based on which we can reason about the consensus security in a rigorous way. Roughly speaking, for any given fraction $\beta$ of malicious nodes, we can find protocol parameters $\tau$  and $\rho$ such that the system is secure. 

\section{Combining Consensus Analysis with Economic Analysis}


Ideally, we want to show that an adversary with a percentage of \emph{storage} lower than $\beta$ cannot break the consensus (assuming that $\tau$ and $\rho$ are chosen in the right way). If we only consider adversaries with storage, then it should follow from the previous analysis. Since adversaries can use a wide range of attacks/resources, we would like to model the adversary capabilities by \emph{disruption tokens}. We then proceed as follows.

{\bf Proof Sketch:} We first show that any deviation from the (farming) protocol results in ``work'', i.e. running the MASK function. The protocol is design this way so it should be fairy straightforward. Ideally we would like to show that the adversary would need to have a complete execution of MASK, but since they can store some parts of the PoS table (in the concrete choice of MASK), this is not possible. Yet, ideally we could show that this is the best the adversary can do. If we succeed, it would give us a lower bound on how much work the adversary should do in order to construct a plot on demand (how many tokens it has to spend). (of course, an adversary can stop creating a table in the middle, but this would result in not having a full plot, and thus affect the probability of success, so it should be easy to handle).

Secondly, our aim is to show that the cost of making plots on demand is higher than storing it. Cost here should be modeled by disruption tokens. As an abstract analysis what we want to show (though it will probably be an assumption in the proof) is that \emph{for some system parameters} ``storage requires less disruption tokens than MASK''.  Finally we would like to show that it holds asymptotically. The conclusion is that an adversary with a fixed budget of disruption tokens can do ``the most harm'' if they spend it all on storage, then we fall into the analysis above.

In the actual implementation of the protocol, one would need to associate cost for storage, cost for MASK, and to argue that in those specific parameters the inequality holds.

\end{document}