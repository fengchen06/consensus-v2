\documentclass[12pt,draftcls,onecolumn]{IEEEtran}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{color}

\newcommand{\Fp}{\mathbb{Z}_p}
\newcommand{\sk}{\texttt{sk}}
\newcommand{\pk}{\texttt{pk}}
\newcommand{\id}{\texttt{id}}
\newcommand{\seed}{\texttt{seed}}
\newcommand{\ind}{\texttt{index}}
\newcommand{\out}{\texttt{output}}
\newcommand{\cmt}{\texttt{commit}}

\newcommand{\Alloc}{\textsc{Alloc}}
\newcommand{\mask}{\textsc{mask}}
\newcommand{\func}{\textsc{func}}
\newcommand{\hash}{\textsc{hash}}

\title{Dilithium: Subspace Consensus v2}
\author{Chen Feng with Subspace R\&D Team}
%\date{December 4 2022}

\begin{document}

\maketitle

\begin{abstract}
    Dilithium is a new Proof-of-Storage consensus protocol designed to provide superior
    user experience while maintaining the highest level 
    of consensus security among existing protocols.
    Developed at Subspace Labs, Dilithium combines KZG polynomial commitment and erasure coding
    in a unique way to achieve unprecedented efficiency. 
    In this paper, we present the fundamental construction of Dilithium
    and outline its security proofs. We also present our initial implementation results to demonstrate the protocol's practicality.
    Our early experimental evaluations show that Dilithium can significantly enhance the user experience while maintaining strong security guarantees, making it a promising candidate for practical deployment.
\end{abstract}

\section{Introduction}

\textit{Proof of storage} is an alternative to proof of work which can be used to secure blockchain networks. An entity, called a \textit{farmer}, contributes disk space as the underlying resource. As such it is minimal on energy consumption. Additionally, as an external resource and widely distributed, it does not suffer from complexities incurred in proof-of-stake-based networks.

Previous proof-of-storage constructions include the work in the proof-of-space Spacemint paper, the proof-of-space-and-time protocol Chia and the proof-of-space-time protocol Spacemesh. These constructions fill the disk space with "cryptographic data", basically chunks of bytes that cannot be used elsewhere besides for the proving protocol, to guarantee the uniqueness of data between different farmers. Filecoin on the other hand is a blockchain based on proof of replication. In Filecoin the aim is to store several copies of a file. For other related works, see Section 1.2 in Spacemint.

Say a few words on the Subspace previous (secure) protocol, and the reason to construct a new one.

[On my end, I would like to emphasize the following after your story.]


Chia is fast but for useless data. Filecoin is slow but for usefull data. Can we have the best of both worlds?

In terms of user experience, we would like to optimize the following metrics
\begin{itemize}
    \item initialization (or setup) time: a few hours to days (depending on the disk space)
    \item proof-generation time: less than one second
    \item proof size: less than 500 Bytes
    \item verification time: much less than one second, ideally in milliseconds
\end{itemize}
At the same time, we aim to achieve the highest level of {consensus security} among existing Proof-of-Storage protocols. 
%We aim to achieve the following objectives

The (relative) small proof size prevents us from using graph-labeling-based constructions (such as those with depth robust graphs used in Filecoin), encouraging us to develop new innovations. We propose to combine three ingredients, namely, polynomial commitment (with constant-size proof size), erasure coding, and function inverting, to address our design challenge. 

\section{Building Blocks of Dilithium}

This section provides an in-depth review of the fundamental building blocks of Dilithium.
We present how Dilithium combines KZG polynomial commitment, erasure coding, and function inverting through a novel concept called \emph{storage coins} to achieve efficiency and security. We discuss the technical details of each building block and explain how they work together to form the overall protocol design. 

\subsection{Creating Storage Coins}

We divide a file $F$ into $n$ pieces $\{ d_0, d_1, \ldots, d_{n-1}\}$, each of equal size\footnote{We can view $F$ as the blockchain history. In general, $F$ grows over time. Here, we only consider the case that $F$ is fixed and defer the general case to our protocol specification.}. 
Without loss of generality, we view each piece as a row vector of length $\ell$ over $\Fp$  (i.e., $d_i \in \Fp^\ell$)\footnote{Here, we choose $\Fp$ because we would like to apply KZG polynomial commitment later.}.
Then, $F$ can be viewed as a matrix of size $n \times \ell$ over $\Fp$.
Alternatively, each piece $d_i$ can be viewed as a polynomial $f_i(x)$ over $\Fp$ of degree at most $\ell - 1$. 
This allows us to view $F$ as a collection of $n$ polynomials $\{ f_i(x) \}_{i = 0}^{n-1}$. 

We assume that each farmer creates a farmer ID $\id$ uniformly at random over some domain. For example, $\id$ can be a (cryptographic) hash output of a farmer's public key $\pk$ (i.e., $\id = H(\pk)$).
We also assume that each farmer selects $m$ pieces (out of $n$ pieces) in a random yet \emph{verifiable} way based on its farmer ID.
We denote these $m$ pieces (or equivalently, polynomials) by $\{g_0^{\id}(x), \ldots, g_{m-1}^{\id}(x) \}$.
For example, each $g_i^{\id}(x)$ can be selected as $f_{(\id + i)\% n}(x)$, where $\% n$ is the mod $n$ operation\footnote{By abuse of notation, we convert $\id$ (from its domain) into an integer here.}.
As another example\footnote{This example corresponds to a standard coupon collector's problem. In order to make sure that every piece is selected by some farmer, we need a total of $O\left( \frac{n \ln n}{m} \right)$ farmers.}, each $g_i^{\id}(x)$ can be selected as $f_{H(\id, i)\% n}(x)$.

We are now ready to explain how a farmer creates storage coins. Let
\[
F^{\id}(x) = \begin{bmatrix} g_0^{\id}(x)\\ g_1^{\id}(x)\\  \vdots \\ g_{m-1}^{\id}(x) \end{bmatrix}
\]
be a column vector of $m$ polynomials. 
Then, we can evaluate $F^{\id}(x)$ at the following $\ell$ points: $\id$, $\id + 1$, $\ldots$, $\id + \ell - 1$\footnote{Again, by abuse of notation, we convert $\id$ into an element in $\Fp$.}.
Each evaluation $F^{\id}(\id + j)$ is a column vector of length $m$ over $\Fp$. We  call it a {\bf storage coin}
associated with $\id$ at point $\id + j$.
For the purpose of efficiency, a farmer can evaluate $\ell$ points simultaneously for every polynomial $g_i^{\id}(x)$
by using some fast polynomial-evaluation algorithms with $\mathcal{O}(\ell \log^2(\ell))$ complexity.
Alternatively, we can evaluate $F^{\id}(x)$ at another set of $\ell$ points: $\id$, $\id \cdot \omega$, $\ldots$, $\id \cdot \omega^{\ell - 1}$, where $\omega$ is a primitive root of unity over $\Fp$ with $\omega^\ell = 1$ or $\omega^{2 \ell} = 1$.


Why is a storage coin useful? If we collect all $\ell$ storage coins associated with $\id$, we can recover $F^{\id}(x)$ through polynomial interpolation.
In particular, if we collect all $\ell$ evaluation points for some polynomial $g_i^{\id}(x)$, we can recover $g_i^{\id}(x)$ through polynomial interpolation.
(There are some fast algorithms for polynomial interpolation with $\mathcal{O}(\ell \log^2(\ell))$ complexity.)
In other words, storage coins allow us to recover some pieces of the file $F$ efficiently. Hence, they represent {\bf useful storage} for $F$.

How can a farmer prove to some verifier that a storage coin $F^{\id}(\id + j)$ at point $\id + j$ is created correctly? This is a standard polynomial commitment problem. For example, we can use the
KZG commitment scheme. Let $A_i$ be the KZG commitment of $f_i(x)$ for $i \in \{0, 1, \ldots, n-1\}$. 
We consider the following two cases.
\begin{enumerate}
    \item The verifier knows $\{ A_i \}_{i = 0}^{n - 1}$. In this case, the farmer just needs to create a KZG proof for the polynomial evaluation $g_i^{\id}(x)$ at point $\id + j$, because the verifier can check whether the choice of polynomial $g_i^{\id}(x)$ is correct. For example, if $g_i^{\id}(x)$ is selected as $f_{(\id + i)\% n}(x)$, the verifier can check whether the KZG proof is consistent with $A_{(\id + i)\% n}$. 
    \item The verifier doesn't know any $A_i$. In this case, we can create a KZG commitment $T$ for $\{ A_i \}_{i = 0}^{n - 1}$ and then give $T$ to the verifier\footnote{Since $A_i$ is not an element in $\Fp$, we cannot apply KZG directly. Instead, we need to hash $A_i$ so that $H(A_i) \in \Fp$.}.  The farmer needs to provide two KZG proofs: one for the polynomial evaluation $g_i^{\id}(x)$ at point $\id + j$ and the other for the correctness of $g_i^{\id}(x)$. (That is, $g_i^{\id}(x)$ is chosen correctly according to our rule. For example, the commitment of $g_i^{\id}(x)$ is indeed $A_{(\id + i)\% n}$, which can be proven by using $T$.)
\end{enumerate}

\subsection{Creating Random Challenges}

We start with a high-level overview. At each time slot (say, one second), every farmer observes some global randomness (also referred to as the global challenge). 
Based on this global challenge, each farmer determines exactly one storage coin (out of $\ell$ storage coins) to scan. Since a storage coin contains $m$ elements in $\Fp$, this gives a farmer $m$ ``tickets'' to win the lottery. A ticket is called a winning ticket if it is close enough to the global challenge in terms of the Hamming distance.

More formally, let $\mathcal{C}_t$ be the global challenge at time slot $t$. Then, each farmer computes
\[
H(\mathcal{C}_t, \id) \mbox{ mod } \ell
\]
in order to decide which storage coin to scan.
For example, if 
\[
H(\mathcal{C}_t, \id) \mbox{ mod } \ell = j,
\]
then the farmer will scan $F^{\id}(\id + j)$, hoping to find a winning ticket (out of $m$ tickets). 
Alternatively, if $\mathcal{C}_t$ and $\id$ share the same domain, each farmer can simply compute
\[
\mathcal{C}_t \oplus \id \mbox{ mod } \ell
\]
to decide which storage coin to scan, since $\oplus$ operation is easier than $H(\cdot)$ operation. 
Once a farmer finds a winning ticket, it can produce a new block.
Clearly, this leader-election mechanism is in spirit similar to Proof-of-Work (one CPU, one vote) and Proof-of-Stake (one coin, one vote).

In the above construction, anyone in the system can figure out whether a particular farmer has a winning ticket, because all the operations depend on the farmer's public key $\pk$ (through $\id$) but not on the secret key $\sk$.  
The construction can be made privacy-preserving as follows. 
Each farmer creates a {\bf local challenge} by signing the global challenge $\mathcal{C}_t$ with its secret key $\sk$. Based on its local challenge, each farmer determines exactly one storage coin (in the same way as before) to find a winning ticket that is close enough to its local challenge. A farmer reveals its local challenge only after a winning ticket is found.

\subsection{Masking Storage Coins}

The previous construction is susceptible to the so-called on-the-fly computing attacks. Specifically, an attacker can store only one copy of $F$
and then ``emulate'' as many farmer IDs as possible by using its computation rather than storage resource.
Essentially, a storage coin $F^{\id}(\id + j)$ is a collection of $m$ polynomial evaluations at point $\id + j$, which can be computed on the fly. 

In order to mitigate this attack, we propose to ``mask" storage coins via function inverting. 
Consider a family of functions $\func_{\seed}: \mathcal{D}_k \to [2^k]$, where $\mathcal{D}_k$ is the domain\footnote{Two examples of $\mathcal{D}_k$ will be given in the next section.} and 
$[2^k] = \{0, 1, \ldots, 2^k - 1 \}$ is the co-domain. Note that both domain $\mathcal{D}_k$ and co-domain $[2^k]$  depend on the parameter $k$.

For simplicity, we assume that $\func_{\seed}(\cdot)$ is surjective in this section (which will be relaxed in later sections). This allows us to define a ``right inverse'' $\mask_{\seed}: [2^k] \to \mathcal{D}_k$ of $\func_{\seed}$ such that for any $\ind \in [2^k]$, we have
\[
\func_{\seed}\left( \mask_{\seed}(\ind) \right) = \ind. 
\]
Essentially, $\mask_{\seed}(\ind)$ returns a pre-image of $\ind$ under $\func_{\seed}$.


Next, we explain how to mask a storage coin
\[
F^{\id}(\id + j) = \begin{bmatrix} g_0^{\id}(\id + j)\\ g_1^{\id}(\id + j)\\  \vdots \\ g_{m-1}^{\id}(\id + j) \end{bmatrix}.
\]
We denote by $\cmt\left(g_i^{\id}(x)\right)$ the KZG commitment of $g_i^{\id}(x)$.
For each $g_i^{\id}(x)$, we set
\[
\seed = \id \oplus H\left( \cmt\left(g_i^{\id}(x)\right) \right).
\]
Then, for any $j \in [2^k]$, we compute $g_i^{\id}(\id + j) \oplus H\left( \mask_{\seed}(j) \right)$ as a masked version of $g_i^{\id}(\id + j)$, denoted by $\tilde{g}_i^{\id}(\id + j)$.
Applying this procedure to all $\{ g_i^{\id}(\id + j) \}_{i = 0}^{m - 1}$, we obtain a {\bf masked storage coin}.
As we will soon see, for the purpose of efficiency, a farmer can mask $\ell$ points for a polynomial $g_i^{\id}(x)$ and then move to another polynomial, say $g_{i+1}^{\id}(x)$.
Alternatively,
we can use $H\left( \mask_{\seed}(j) \right)$ to mask $g_i^{\id}(\id \cdot \omega^j)$ instead of $g_i^{\id}(\id + j)$, where $\omega$ is a primitive root of unity\footnote{In the C-KZG library, $\omega$ is chosen such that $\omega^{2 \ell} = 1$.}.

Why is the masking function $\mask_{\seed}(\cdot)$ useful? First, the attacker has to invert $m$ functions on-the-fly in order to emulate a masked  storage coin. This requires excessive space-time resources, as we will see later.
Second, the attacker cannot reuse its space-time resources to emulate different farmer IDs. In particular, even if two farmer IDs have a same polynomial in common, the attacker still needs to invert two different functions (because of the difference in $\seed$). 


\subsection{Putting Everything Together}

We are now ready to put all the building blocks together. Recall that the file $F$ consists of $n$ pieces $\{d_i\}_{i = 0}^{n-1}$, which can be viewed as $n$ polynomials $\{ f_i(x) \}_{i = 0}^{n-1}$. Recall that
$A_i$ is the KZG commitment of $f_i(x)$ and $T$ is the KZG commitment of $(H(A_0), \ldots, H(A_{n-1}))$. We assume that $T$ is public information.
Let $\pi_i$ be the KZG proof for $H(A_i)$. With $\pi_i$, anyone in the system can verify whether $A_i$ is consistent with the public information $T$.

Each farmer generates a key pair $(\sk, \pk)$ and derives its farmer ID $\id$ (e.g., $\id = H(\pk)$).
With a given $\id$, the farmer selects $m$ polynomials $\{g_i^{\id}(x) \}_{i = 0}^{m - 1}$ and retrieves their KZG commitments $\{\cmt\left(g_i^{\id}(x) \right \}_{i = 0}^{m - 1}$
together with the proofs with respect to $T$. Then, the farmer creates $\ell$ storage coins 
$\{ F^{\id}(\id + j) \}_{j = 0}^{\ell - 1}$ and generates their masked versions by using the function $\mask_{\seed}(\cdot)$ as described before.
Finally, the farmer stores $\ell$ masked storage coins as well as some metadata (i.e., $m$ commitments $\{\cmt\left(g_i^{\id}(x) \right \}_{i = 0}^{m - 1}$ together with their proofs).
This process is often called {\bf plotting} in the Proof-of-Storage literature.

Recall that a global challenge $\mathcal{C}_t$ is generated at time slot $t$, based on which each farmer selects one masked storage coin and collects $m$ lottery tickets from it. If a farmer finds a winning ticket, it has to prove the following
\begin{itemize}
    \item the winning ticket (say, $\tilde{g}_i^{\id}(\id + j)$) is indeed close enough to $\mathcal{C}_t$
    \item the unmasked element ${g}_i^{\id}(\id + j)$ is correct
\end{itemize}
This process is called {\bf farming} in the literature. 

The above construction provides a leader-election mechanism, which can be combined with some longest chain protocol to produce a consensus algorithm.

% \subsection{Advantages of Our Construction}

% Here, we summarize several advantages of our proposed construction before conducting a formal analysis.
% \begin{enumerate}
%     \item The use of storage coins enlarges the design space. In PoR, a file is the smallest unit. In the ECP paper, a RS coded piece is the smallest unit. In our construction, a polynomial coded piece is the smallest unit.
%     \item The enlarged design space makes it easier for us to choose good parameters.
%     \item The usefulness of storage coins can be verified through standard KZG, which implies low communication and fast verification.
%     \item Unlike proof-of-replication, farmers have more incentives to store encodings $\{ R_j(\id) \}_{j = 1}^L$ because these encodings are lottery tickets (which are hard to compute on-the-fly).
%     \item Once a farmer has one storage coin, it can participate in the lottery.
%     \item Storage coins support a dynamic setting.
%     \item The size of a storage coin is relatively small, making it easier to apply slow encoding. I suspect that even the second solution described above might be sufficient.
% \end{enumerate}




\section{Extensions}

Our basic construction assumes that $\func_{\seed}(\cdot)$ is surjective. In this section, we explain how to relax this assumption through two examples.

% relies on an ``ideal'' function $\mask(\cdot)$ that has three properties. The first two properties are easy to achieve, but not the third one. Indeed, we don't have a concrete example of $\mask(\cdot)$ at the time of writing. Instead, we have a weaker version of $\mask(\cdot)$ in which the third property is relaxed. In this version, $\seed$ and $k$ determine a random function $h(\cdot)$ that requires a significant amount 
% of space to invert, and the output of $\mask(\cdot)$ is a pre-image of $\ind$ under $h$. Since the pre-image (of $\ind$ under $h$) can be empty or a set with multiple elements, the output of $\mask(\cdot)$ is not always a single value. We would like to show that this is not an issue.
% To this end, we consider three possible examples of $\mask(\cdot)$.

\noindent {\bf Example 1:} Construct $\func_{\seed}: [2^k] \to [2^k]$ as 
\[
\func_{\seed}(x) = \hash(\seed \| x),
\]
where $\|$ denotes concatenation and $\hash: [*] \to [2^k]$ is a cryptographic hash function.
Then, under the random oracle model, for any given $\seed$, $\func_{\seed}: [2^k] \to [2^k]$ is a random function 
that maps an input in $[2^k]$ to an output uniformly chosen from $[2^k]$.

Let $\ind \in [2^k]$. We have the following two cases.
\begin{enumerate}
    \item $\ind$ has at least one pre-image under $\func_{\seed}$. In this case, $\mask_{\seed}(\ind)$ is well defined and we simply mask $g_i^{\id}(\id + \ind)$ as we did before.
    \item $\ind$ has no pre-image under $\func_{\seed}$. In this case, $\mask_{\seed}(\ind)$ doesn't exist and we cannot mask $g_i^{\id}(\id + \ind)$, leavng it unmasked.
\end{enumerate}
Then, for each storage coin $F^{\id}(\id + \ind)$ at point $\id + \ind$, we only store its masked elements (and discard its unmasked elements).

Previously, we need a total of $\ell$ storage coins (in order to recover the original pieces). How many storage coins do we need now?
Clearly, this number $L$ should be between $\ell$ and $2^k$ (i.e., $\ell < L \le 2^k$).
In fact, this question is closely related to the balls-and-bins problem. 
Suppose that we have $2^k$ balls and $2^k$ bins with each ball placed into a bin uniformly at random and independent of each other.
Then, the fraction of empty bins is approximately $\frac{1}{e}$ for large $2^k$.
In other words, the fraction of non-empty bins is approximately $1 - \frac{1}{e}$.
This implies that $\frac{\ell}{L} \ge 1 - \frac{1}{e}$ if we would like to have at least $\ell$ non-empty bins out of the first $L$ bins. 
In fact, the probability of an ``error event'' (of having fewer than $\ell$ non-empty bins out of the first $L$ bins) can be approximately bounded by $\exp\left(- 2^k D_{KL}(1 - \ell/L, 1/e) \right)$. The larger $L$ is, the larger the term $D_{KL}(1 - \ell/L, 1/e)$ is, and the smaller the error probability.
This can be used as a guideline for choosing $L$.

%To see this, on the one hand, the fraction of empty bins is approximately $1/e$ for large $k$, and on the other hand, the fraction of non-empty bins should be no smaller than $\ell/2^{k}$ in order to ``mask'' $\ell$ polynomial evaluations.
%(To do: cite more results here.)

%A concern here: the variance creates grinding opportunities (because the number of tickets is no longer fixed). Luckily, we can show that the variance is indeed small.

\noindent {\bf Example 2:} Let $p: [2^k] \to [2^k]$ be a random permutation. Define the domain $\mathcal{D}_k \subset [2^k] \times [2^k]$ as the set 
\[
\{ (x_1, x_2) : p(x_1) = \pi\left( p(x_2) \right) \},
\]
where $\pi$ can be any involution without a fixed point (e.g., flipping all the bits).
Construct $\func_{\seed}: \mathcal{D}_k \to [2^k]$ as 
\[
\func_{\seed}(x_1, x_2) = \hash(\seed \| x_1 \| x_2).
\]

In Example~2, we can view any $(x_1, x_2) \in \mathcal{D}_k$ as a ball and so
our analysis for Example~1 still applies here. 
Note that $\mask_{\seed}(\cdot)$ here returns an element in $\mathcal{D}_k$ instead of $[2^k]$.
%Also, a pre-image of $h(\cdot)$ is of the form $(x, x')$ rather than $x$ only, because otherwise the verifier has to find $x'$.

There are some interesting space-time lower bounds in the literature 
related to Examples~1 and 2. 

\noindent {\bf Lower Bound 1:}
For any oracle-aided algorithm $\mathcal{A}$, it holds that for most random functions
$\func: [2^k] \to [2^k]$, if $\mathcal{A}$ is given advice (that can arbitrarily depend on $\func$)
of size $S$, makes at most $T$ oracle queries and inverts $\func$ on $\epsilon 2^k$ values, we have
\begin{equation}
    S \cdot T \in \Omega\left(\epsilon 2^k \right).
\end{equation}


\noindent {\bf Lower Bound 2:}
For any oracle-aided algorithm $\mathcal{A}$, it holds that for most functions
$\func: \mathcal{D}_k \to [2^k]$ constructed in Example~2, if $\mathcal{A}$ is given advice (that can arbitrarily depend on $\func$)
of size $S$, makes at most $T$ oracle queries and inverts $\func$ on $\epsilon 2^k$ values, we have
\begin{equation}
    S^2 \cdot T \in \Omega\left(\epsilon^2 2^{2k} \right).
\end{equation}

However, Lower Bound~2 only applies when $T \le \left(2^k/4 e \right)^{2/3}$. This restriction seems to be mostly related to the proof technique. Here, we conjecture that it still holds even when $T > \left(2^k/4 e \right)^{2/3}$.

Let us compare these two lower bounds. For simplicity, we set $\epsilon = 1$ and $S = \sqrt{2^k}$. Then, Lower Bound~1 says that 
$T \in \Omega\left(\sqrt{2^k} \right)$ and Lower Bound~2 states that $T \in \Omega\left( 2^k \right)$.
That is, Lower Bound~2 requires significantly longer time $T$ under the same amount of space $S$, because the function in Example~2 is more complicated than that in Example~1.
Intuitively, we can achieve a better lower bound 
\[
S^q \cdot T \in \Omega\left(\epsilon^q 2^{qk} \right)
\]
with $q \ge 3$ if we make the function $\func$ even more complicated. A particular approach is given in [X], which is the key idea behind the Chia project.

% {\bf Example 3:} $h(\cdot)$ is constructed via Chia PoS tables. In this example, an output is of the form $(x_1, x_2, \ldots, x_{64})$. Assume that all seven functions $f_1(x), \ldots, f_7(x)$  are random functions.
% Then, for any \emph{weakly distinct} tuple $(x_1, x_2, \ldots, x_{64})$, the probability it passes the challenge is $2^{-64k}$.
% Note that in Example~2, for any \emph{weakly distinct} tuple $(x_1, x_2)$, the probability it passes the challenge is approximately $2^{-2k}$. Therefore, our analysis for Example~2 is a good approximation.

Finally, recall that the number of storage coins $L$ satisfies $\ell < L \le 2^k$. Since we need to invert $\func(\cdot)$ on $L$ values (for $\ind \in \{0, 1, \ldots, L - 1 \}$), we can rewrite the above lower bound in a simpler form 
\begin{equation}\label{eq:general_bound}
    S^q \cdot T \in \Omega\left(L^q \right).
\end{equation}

In the plotting phase, we essentially find pre-images of all $L$ values  and then XOR a pre-image of $\ind$ (if it exists) with the corresponding polynomial evaluation at $\id + \ind$. 
This corresponds to one extreme case of the space-time lower bound where we set $S = L$.
On the other hand, on-the-fly computing corresponds to the other extreme case where we set $S = 1$ and obtain $T \in \Omega\left(L^q \right)$.


We now understand the extensions of our basic construction. Before conducting a formal analysis, let us present several possible attacks and their mitigation methods in order to better understand our construction.

{\bf Attack 1:} If $\mask_{\seed}(\cdot)$ returns multiple outputs, an attacker can produce multiple tickets instead of one.

\begin{itemize}
    \item Mitigation Method 1: If the verifier can figure out which output is the first, then this issue can be resolved.
    \item Mitigation Method 2: We allow the farmers to produce multiple tickets from multiple outputs. This introduces some randomness, which can be bounded by using the analysis above.
\end{itemize}

{\bf Attack 2:} The attacker stores the Chia PoS tables on disk instead of the masked storage coins.

\begin{itemize}
    \item Mitigation Method 1: We can choose $k$ so that Chia PoS tables are sufficiently larger than the corresponding masked storage coins.
    \item Mitigation Method 2: We estimate the amount of additional disk look-ups and then use an economic security argument.
\end{itemize}

{\bf Attack 3:} The attacker stores the Chia PoS tables on memory.

\begin{itemize}
    \item We show that the memory storage cost is larger than the disk storage cost.
\end{itemize}

{\bf Note:} Both Attack 2 and Attack 3 can be well mitigated by using a large $k$. However, we have some practical upper bound on $k$. So, we need a {\bf tight analysis} to show that a relatively small $k$ is still OK.

{\bf Attack 4:} The attacker exploits the case of expiring pieces. Since this case is not considered in our current model and analysis, there might be some potential attacks here.

%{\bf Attack 5:} On DSN load balancing.




\section{Consensus Security Analysis}

In this section, we conduct an initial security analysis based on the previous space-time lower bound.
Our key observation is twofold. First, the previous lower bounds capture the amount of resources one needs 
to have in order to fake storage coins. Second, our previous Proof-of-Storage construction can be analyzed
by using the general framework proposed by XXX.

\subsection{System Model}

%On Explicit Constructions of Extremely Depth Robust Graphs
%ZigZag horizontal DRG + vertical DRG
%Temporary Block Withholding Attacks on Filecoin's Expected Consensus

The protocol proceeds in slots of duration $\tau$ as explained before. For simplicity, we consider a fixed set of $N$ farmers (or nodes) with equal capability. We
are particularly interested in the large system regime $N \to \infty$. In each slot, each farmer can win the lottery with probability $\rho / N$,
independently of other farmers and slots. When a malicious farmer wins the lottery at slot $t$, it can create multiple blocks, which is a behavior called equivocations. (Note that equivocations never happen in Proof-of-Work protocols but can appear in our construction.)

\subsection{Faking Storage Coins}

The previous lower bound \eqref{eq:general_bound} suggests the following. In order to fake $L$ storage coins of a farmer (i.e., faking a farmer ID), one needs $mS$
amount of space and makes at most $mT$ oracle queries with $S^q \cdot T \in \Omega\left(L^q \right)$. 
This allows us to compare our construction with Chia, since the lower bound \eqref{eq:general_bound} applies to both.
Using our notation, the parameter setup in Chia can be described as $k = 32$, $L = 2^{32}$, $m = 1$, and $q = 6$. 
In our setup, we can choose $k = 16$, $m = 2^{16}$, and $q = 12$ to conduct a fair comparison, 
because the required disk space is proportional to $m L$.
Under the above setups, on-the-fly computing requires at most $\Omega\left( 2^{192} \right)$ oracle queries to fake a farmer ID in Chia,
while it requires at most $2^{16} \Omega\left(2^{192}\right)$ oracle queries in our construction. 
Similarly, an attacker $\mathcal{A}$ with space $S$ needs to make at most $\Omega\left( \frac{2^{192}}{S^6}  \right)$
oracle queries in order to fake a farmer ID in Chia, whereas an attacker $\mathcal{A}'$ with space $m \sqrt{S}$
needs to make at most $m \Omega\left( \frac{2^{192}}{S^6}  \right)$ oracle queries in our construction.
This implies that our construction is more resilient than Chia under the above setups, since we always have $m \ge \sqrt{S}$.

\section{Combining Consensus Analysis with Economic Analysis}

Aim: to show that the cost of participation in the consensus protocol is lowest when following the protocol (dedicating storage for plotting).

Expense tokens: for formality we use the abstract notion of "expense tokens" to represent the cost of participation in farming.

Method: the analysis is reduced to measuring the cost of obtaining a single ``lottery ticket''.

Framework: we adopt the random-oracle model, and assume the hash functions being used in the protocol are random oracles. Hence, sectors are independent and so the analysis for a single sector suffices.

{\bf Claim I:} Consider a farmer with $r$ sectors. For any $c$, let $C_{r-1}$ be the cost of obtaining $c(r-1)$ lottery tickets in the 'first' $r-1$ sectors. Then, the cost of obtaining $c$ tickets in the remaining sector is $C_{r-1}/r$. In other words, the farming-costs per sector are equal.

(we also need to show that the protocol is "cryptographically secure" in the sense that one has to plot in order to obtain a ticket, that is one cannot break the system and obtain tickets without plotting)

{\bf Claim II:} Farmers needs to plot sectors in order to participate in consensus.


\textbf{Part I: abstract MASK function}

\textbf{Framework}

- We assume that the adversary has the entire raw history (archived), and assign it a negligible cost / we don't consider it to be part of the available storage $S$ (the reason is that for any history size, $S$ can be arbitrary large, making the history size insignificant).

- The plotting function MASK is parameterized by a value $k$. Running MASK with larger $k$ costs more expense tokens.

- We treat MASK as a block box. That is, one cannot "open" it, but only enter inputs and receive outputs. Hence, for a fixed $k$, MASK has a fixed cost per invocation.



We explain that any deviation from the (farming) protocol results in creating more sectors, hence running MASK more times.

{\bf Claim III:} Consider a farmer $F$ with storage $S$ and let $r = S/(sector-size)$. Suppose that a sector gives $c$ tickets per challenge/slot. For any challenge, if $F$ obtains more than $cr$ tickets, then $F$ created more than $r$ sectors.

{\bf proof sketch:} The protocol is designed such that any deviation requires running MASK, essentially creating a new plot.


{\bf Claim IV:} Suppose that a sector gives $c$ tickets per challenge. Let $T_S$ be the cost of obtaining $c$ lottery tickets with a single sector following the farming protocol. Let $T^*$ be the cost of obtaining $c$ lottery tickets in a hybrid strategy that combines storage and compute. Then $T^* \geq T_S$.**

** we eventually want to show that there is order(s) of magnitude difference such that if storage cost raises, the claim still holds.


{\bf Proof outline:}

Consider the hybrid strategy:

- By Claim II, since the farmer obtains $c$ tickets, it has to create at least one sector.

- By the proof of Claim III, since the farmer does not follow the farming protocol it must create at least another sector, resulting in running MASK.

- MASK is parameterized by a ''difficulty'' parameter $k$. As $k$ grows, running MASK costs more tokens (recall that also the honest party has to run it once per plotting phase).

- We can set $k$ large enough s.t. running it twice costs (significantly) more than $T_S$.

\textbf{Discussion:} The previous claim shows that the marginal cost of farming honestly, once a sector is created, is lower than (seleting and) creating another sector. This is because obtaining more tickets per challenge requires running MASK, which is designed to consume more tokens. Hence, it is best to run MASK (plot sectors) as little as possible, and only pay the ongoing cost. 

This, however, does not take into account a farmer that consumed all of its storage and still has tokens to spare. We would like to show that in this case the farmer better purchase more disk space and follow the farming protocol (assuming the amount of tokens left is not negligible). The modification to the claim above is very little, where we make sure that $k$ is large enough to account for this extra cost, amortised on the potential sectors.




\textbf{Part II: the actual MASK function}



\textbf{Part III: 'security' of the PoAS in the concrete blockchain design}
(if we see fit this may be combined with Part II)


Comments (for ourselves as we discuss this):

- The only subtle issue is that some costs are amortised among many sectors, like the hardware (even though compute hardware is modeled to be 0 cost for the attacker).

- How we measure cost: we have the freedom to define "cost of storage" as we wish, but we should make sure that it is well defined. Since hardware storage and plotting is amortised among many challenges, the formal definition should not depend on these.

- explain what we mean by cost of storage: keep abstract -- the cost captures "whatever the overall cost is": includes HD cost, plotting -- we can break into fixed + ongoing costs

- if we succeed in making the claim generic enough then the conclusion holds for \textit{any time frame} in which the (honest) farmer decide to spend their entire token budget (that is, the honest farmer can plot a single sector and let it consume expense token "slowly" or she can plot as many sectors as the storage he has let her, consuming more tokens).

\end{document}

\section{Economic Security Analysis}

%\subsection{System model}

{\bf Outline:} We can use a hardware architecture model to reason about economic security. In particular, we will focus on the memory IO and Hash computation (modelled as an oracle access). We will model the energy cost as a linear combination of the memory IO and oracle access and then derive a lower bounder for the energy cost. We will then include the setup cost. Similar models have already been used in Ling Ren's PhD thesis and other works.



{\bf Intuition:} First of all, we consider three very simple cases.
\begin{itemize}
    \item If an attacker generates the Chia PoS tables on the fly, then the memory IO is lower bounded by the size of the tables.
    \item If an attacker stores the Chia PoS tables on memory, then the memory storage cost is higher than the disk storage cost.
    \item If an attacker stores the Chia PoS tables on disk, then we can make the size of tables larger than the masked storage coins.
\end{itemize}

Next, for Hellman's attacks, we can lower bound their memory IO and computational costs.
Here, we need to consider more general attacks because the attacking goal here is to minimize the total cost.

{\bf Proof Sketch:} Our proof is based on the following ingredients. 

\begin{itemize}
    \item Space-time tradeoff lower bound (from the ``Beyond Hellman'' paper): 
    any adversary who gets $S$ bits of auxiliary information, makes at most $T$
    oracle queries, and inverts $h(\cdot)$ (defined in Example~2 above) on an
    $\epsilon$ fraction of outputs must satisfy $S^2 \cdot T \in \Omega(\epsilon^2 N^2)$ (where $N$
    is the domain size and $N = 2^k$ in our notation).
    \item Energy cost in the parallel random oracle model (from the ``Bandwidth-Hard Functions'' paper): a formal definition of energy costs is given based on a simple memory-cache model.
\end{itemize}

Roughly, $S$ bits of auxiliary information can be computed in cache and then transferred to memory (which incurs memory IO with a unit cost $c_b$), and $T$ oracle queries can be charged with a unit cost $c_r$.
This allows us to evaluate the energy cost for any adversary. Note that this cost depends on $k$, which can be adjusted so that the cost is higher than the energy cost of honest farmers.

\section{Consensus Security Analysis}

Our key inspirations are the following.

\begin{itemize}
    \item When considering longest-chain protocols, Proof-of-Stake (PoS) is less secure than PoW as it presents many additional vulnerabilities (such as long-range attacks). 
    \item The best we can show is that Proof-of-Archival-Storage (PoAS) stands in the middle.
\end{itemize}

\subsection{System model}

%On Explicit Constructions of Extremely Depth Robust Graphs
%ZigZag horizontal DRG + vertical DRG
%Temporary Block Withholding Attacks on Filecoin's Expected Consensus

The protocol proceeds in slots of duration $\tau$ (where $\tau$ is one second in our PoAS setup). For simplicity, we consider a fixed set of $N$ nodes with equal capability. We
are interested in the large system regime $N \to \infty$. In each slot, each node can win the lottery with probability $\rho / N$,
independently of other nodes and slots. When a malicious node wins the lottery at slot $t$, it can create multiple blocks, which is a behavior called equivocations. (Note that equivocations never happen in PoW but can appear in PoS and PoAS.)




\subsection{Proof outline}


Following the paper ``Security of Blockchains at Capacity'' (which is available online),  we can define \emph{good} slots, \emph{bad} slots, and \emph{empty} slots based on which we can reason about the consensus security in a rigorous way. Roughly speaking, for any given fraction $\beta$ of malicious nodes, we can find protocol parameters $\tau$  and $\rho$ such that the system is secure. 
Note that the security proof assumes that certain download rules are used by the underlying P2P network. This assumption is reasonable because the download rules are relatively easy to implement.

Next, we need to understand how to emulate storage coins so that a malicious node can win the lottery with probability $\rho / N$.
Essentially, it is a function inverting problem. One can compute the function table at the very beginning and then store the entire table in SSD (in the form of transformed pre-images). Alternatively, one can compute the function table and then only store part of the table in SSD (in any form).
I feel that we just need to focus on the block production opportunity (BPO). In particular, each BPO implies some space-time tradeoff. This completes the proof.

\subsection{Intuitions}
Here, we will explain why the above proof outline works. The BPO is defined as a pair $(p, t)$ where node $p$ wins the lottery associated with slot $t$ and so is eligible to produce a block. To track the system evolution, we can introduce two random variables $H_t$ and $A_t$ denoting the number of honest and adversarial BPOs in slot $t$, respectively. For simplicity, we assume that blocks in one chain must come from increasing slots. This can be achieved by imposing a constraint on the longest chain protocol. In addition, we assume that honest nodes download at most one block per BPO. This can be achieved by using some specific download rule (called equivocation removal policy) proposed in the paper ``Security of Blockchains at Capacity''.

Following the footsteps of the paper, we can define empty slots and non-empty slots. For a non-empty slot, we can classify it into a good slot or a bad slot. In other words, the proof steps of ``Security of Blockchains at Capacity''  are compatible with our construction. 

Finally, we have the following observations.
\begin{itemize}
    \item The parameter $\rho$ doesn't depend on the adversarial action (assuming that the common randomness is not affected by adversarial action). This is because a transformed pre-image is a ticket and only the number of pre-images matters. 
    \item The proof in ``Security of Blockchains at Capacity'' is based on a counting argument that captures a large range of attacks.
\end{itemize}

Therefore, we only need to understand the ``cost'' of emulating a node that wins the lottery with probability $\rho / N$. 

\textbf{OLD version}

Ideally, we want to show that an adversary with a percentage of \emph{storage} lower than $\beta$ cannot break the consensus (assuming that $\tau$ and $\rho$ are chosen in the right way). If we only consider adversaries with storage, then it should follow from the previous analysis. Since adversaries can use a wide range of attacks/resources, we would like to model the adversary capabilities by \emph{disruption tokens}. We then proceed as follows.

{\bf Proof Sketch:} We first show that any deviation from the (farming) protocol results in ``work'', i.e. running the MASK function. The protocol is design this way so it should be fairy straightforward. Ideally we would like to show that the adversary would need to have a complete execution of MASK, but since they can store some parts of the PoS table (in the concrete choice of MASK), this is not possible. Yet, ideally we could show that this is the best the adversary can do. If we succeed, it would give us a lower bound on how much work the adversary should do in order to construct a plot on demand (how many tokens it has to spend). (of course, an adversary can stop creating a table in the middle, but this would result in not having a full plot, and thus affect the probability of success, so it should be easy to handle).

Secondly, our aim is to show that the cost of making plots on demand is higher than storing it. Cost here should be modeled by disruption tokens. As an abstract analysis what we want to show (though it will probably be an assumption in the proof) is that \emph{for some system parameters} ``storage requires less disruption tokens than MASK''.  Finally we would like to show that it holds asymptotically. The conclusion is that an adversary with a fixed budget of disruption tokens can do ``the most harm'' if they spend it all on storage, then we fall into the analysis above.

In the actual implementation of the protocol, one would need to associate cost for storage, cost for MASK, and to argue that in those specific parameters the inequality holds.
